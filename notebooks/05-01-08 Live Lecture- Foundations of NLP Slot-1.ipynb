{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd927a42-e488-441d-afa0-053a66f466f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cases: Text Processing, Text Cleaning, Spell Corrections, String Similarity (Semantics), Text Classification etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42f45c-64ab-4a0a-a58b-26e62039d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Processing - \"Lexicon\" --> words--> order, grammar, context does not matter (text classification)\n",
    "# Syntactic Processing - \"Syntax\" --> order, grammar matters (POS tags, NER tags)\n",
    "# Semantic Processing - \"Semantics\" --> \"Similarity\" --> order, grammar, context everything matters (Chat bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb11950f-b4f1-434f-8553-4d20adf7396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk #natural language toolkit\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efd43ab-cd48-4232-b81d-d6f359efbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29daa8e-f39c-4241-aa7a-c3545e384217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenisation, stemming, lemmatisation, puntuation removal, case folding etc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bea2b88-cbab-4481-96be-77deefdd7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"LOL!!! I can't believe this happened ðŸ˜± #funny #shock\",\n",
    "    \"Python is AWESOME!!! :) Check out python.org\",\n",
    "    \"RT @user: Working on NLP projects is sooo cool!!!\",\n",
    "    \"Iâ€™m loving it... but sometimes itâ€™s frustrating!!! ðŸ˜…\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e0cc0a-42af-4c63-93ae-6882863f44f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivamgarg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shivamgarg/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #pre-trained model required for tokenisation\n",
    "nltk.download('wordnet') #model required for lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc34f2f9-160f-40bf-9fc7-9980688c52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tweets:\n",
      "\n",
      "- LOL!!! I can't believe this happened ðŸ˜± #funny #shock\n",
      "- Python is AWESOME!!! :) Check out python.org\n",
      "- RT @user: Working on NLP projects is sooo cool!!!\n",
      "- Iâ€™m loving it... but sometimes itâ€™s frustrating!!! ðŸ˜…\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Tweets:\\n\")\n",
    "for t in tweets:\n",
    "    print(\"-\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9625a93-952d-412b-a9ab-3bd5c1826f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) CASE FOLDING\n",
    "def case_folding(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c9ed05c-3797-4aa0-adea-42b26dc4aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) PUNCTUATION REMOVAL\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([ch for ch in text if ch not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a223ee7-b11e-424e-91de-55b8a75c8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) TOKENISATION\n",
    "def tokenise(text):\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "385f1e70-299a-4a4f-9460-8f3c30d64468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) STEMMING - Rule based approach\n",
    "#task, tasked, tasking, credit, credited, mangoes\n",
    "def stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words=tokenise(text)\n",
    "    return ' '.join([stemmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ddbc8d7-a640-43a0-a46d-77f3daed84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e) LEMMATIZATION - Corpus based approach\n",
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words=tokenise(text)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f2fe5-5a19-4b80-9021-e831a4a789b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence and seletion of operation to be chosed basis the requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fdab597-3102-4960-a33c-bab779de25d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Original: LOL!!! I can't believe this happened ðŸ˜± #funny #shock\n",
      "lol!!! i can't believe this happened ðŸ˜± #funny #shock\n",
      "lol i cant believe this happened ðŸ˜± funny shock\n",
      "lol i cant believ thi happen ðŸ˜± funni shock\n",
      "lol i cant believe this happened ðŸ˜± funny shock\n",
      "------------------------------------------------------------\n",
      "Original: Python is AWESOME!!! :) Check out python.org\n",
      "python is awesome!!! :) check out python.org\n",
      "python is awesome  check out pythonorg\n",
      "python is awesom check out pythonorg\n",
      "python is awesome check out pythonorg\n",
      "------------------------------------------------------------\n",
      "Original: RT @user: Working on NLP projects is sooo cool!!!\n",
      "rt @user: working on nlp projects is sooo cool!!!\n",
      "rt user working on nlp projects is sooo cool\n",
      "rt user work on nlp project is sooo cool\n",
      "rt user working on nlp project is sooo cool\n",
      "------------------------------------------------------------\n",
      "Original: Iâ€™m loving it... but sometimes itâ€™s frustrating!!! ðŸ˜…\n",
      "iâ€™m loving it... but sometimes itâ€™s frustrating!!! ðŸ˜…\n",
      "iâ€™m loving it but sometimes itâ€™s frustrating ðŸ˜…\n",
      "i â€™ m love it but sometim it â€™ s frustrat ðŸ˜…\n",
      "i â€™ m loving it but sometimes it â€™ s frustrating ðŸ˜…\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    print(\"---\"*20)\n",
    "    print(\"Original:\", tweet)\n",
    "    out1=case_folding(tweet)\n",
    "    print(out1)\n",
    "    out2=remove_punctuation(out1)\n",
    "    print(out2)\n",
    "    out3=stemming(out2)\n",
    "    print(out3)\n",
    "    out4=lemmatization(out2)\n",
    "    print(out4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da69d911-3551-4158-80fa-02faac524392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b11aa71a-90cd-4191-add7-c6b6a6cf1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=\"eating\"\n",
    "s2=\"sitting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d124758e-600a-462c-a44a-677ce61377f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "distance = edit_distance(s1, s2)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b8a6b7-c335-4bd6-b34a-1a0b93163d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
