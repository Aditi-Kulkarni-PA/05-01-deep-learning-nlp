{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6fc2ae",
   "metadata": {},
   "source": [
    "# Summary - Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4595b96",
   "metadata": {},
   "source": [
    "| **Aspect**                  | ğŸ§± **Lexical Processing**                                                                                        | ğŸ—ï¸ **Syntactic Processing**                                                                                        | ğŸ’¡ **Semantic Processing**                                                                                                                             |\n",
    "| --------------------------- | ---------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Level of Analysis**       | **Word-level**                                                                                                   | **Sentence-level (structure)**                                                                                      | **Meaning-level (concepts)**                                                                                                                           |\n",
    "| **Primary Focus**           | Deals with **individual words and their forms**                                                                  | Deals with **how words combine grammatically**                                                                      | Deals with **what the sentence actually means**                                                                                                        |\n",
    "| **Goal**                    | Clean, normalize, and prepare tokens for analysis                                                                | Identify **grammatical structure** and relationships                                                                | Extract **meaning, roles, and context**                                                                                                                |\n",
    "| **Order of Words**          | âŒ **Does NOT matter** (bag-of-words view)                                                                        | âœ… **Matters** (grammar depends on order)                                                                            | âœ… **Matters** (meaning depends on structure and context)                                                                                               |\n",
    "| **Main Operations / Tasks** | - Text normalization<br>- Tokenization<br>- Stopword removal<br>- Stemming / Lemmatization<br>- Spell correction | - POS tagging<br>- Chunking (NP, VP, PP)<br>- Constituency / Dependency parsing<br>- Grammatical agreement checking | - Semantic role labelling (who did what)<br>- Word sense disambiguation (WSD)<br>- Coreference resolution<br>- Semantic parsing<br>- Textual inference |\n",
    "| **Input**                   | Raw or cleaned text                                                                                              | Tokenized, tagged text                                                                                              | Parsed, structured text                                                                                                                                |\n",
    "| **Output**                  | Tokens, lemmas, normalized words                                                                                 | Parse trees, dependency graphs, POS tags                                                                            | Semantic frames, role graphs, meaning representations                                                                                                  |\n",
    "| **Representation**          | Words or morphemes                                                                                               | Phrases, grammatical links                                                                                          | Logical or conceptual relationships                                                                                                                    |\n",
    "| **Example Sentence**        | â€œThe cats are running.â€ â†’ `[the, cat, are, run]`                                                                 | [NP The cats] [VP are running]                                                                                      | agent(cats), action(run), time(now)                                                                                                                    |\n",
    "| **Knowledge Used**          | Morphological / lexical knowledge                                                                                | Grammatical / syntactic rules                                                                                       | Contextual / world knowledge                                                                                                                           |\n",
    "| **Common Tools**            | Tokenizers, stemmers, lemmatizers, spell checkers                                                                | POS taggers, CFG parsers, dependency parsers                                                                        | SRL systems, WordNet, BERT-based semantic models                                                                                                       |\n",
    "| **Type of Rules / Models**  | Rule-based or statistical (surface-level)                                                                        | Grammar-based or probabilistic (structural)                                                                         | Semantic / contextual (deep models)                                                                                                                    |\n",
    "| **Output Type**             | Clean tokens                                                                                                     | Structured syntax tree                                                                                              | Meaning graph / logical form                                                                                                                           |\n",
    "| **Typical Errors**          | Misspellings, inconsistent forms                                                                                 | Incorrect POS tags or parse trees                                                                                   | Misinterpreted context or ambiguity                                                                                                                    |\n",
    "| **Applications**            | Preprocessing, IR, indexing, text cleaning                                                                       | Grammar checking, translation alignment, syntax-based QA                                                            | Chatbots, question answering, summarization, semantic search                                                                                           |\n",
    "| **Example of Sensitivity**  | â€œcat dog runâ€ = â€œdog run catâ€ (same tokens)                                                                      | â€œdog chased catâ€ â‰  â€œcat chased dogâ€                                                                                 | â€œJohn gave Mary a giftâ€ â‰  â€œMary gave John a giftâ€                                                                                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c3caa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6557319",
   "metadata": {},
   "source": [
    "# Complete NLP Pipeline â€” Step-by-Step Transformation Table\n",
    "\n",
    "| **Stage**                      | **Process / Concept**                                 | **Description / Operation**                                                                                               | **Example Input â†’ Output**                                                                                        |\n",
    "| ------------------------------ | ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
    "| **1ï¸âƒ£ Lexical Processing**     | **Raw Input**                                         | Start with natural, noisy text (includes contractions, punctuation, emoji).                                               | â€œRiya didnâ€™t give her friend any gfits yesterday ğŸ˜Š.â€                                                             |\n",
    "|                                | **Text Normalisation**                                | Lowercasing, punctuation cleanup, encoding fix.                                                                           | â€œriya didnâ€™t give her friend any gfits yesterday ğŸ˜Šâ€                                                              |\n",
    "|                                | **Contraction Expansion**                             | Expand shortened forms (important for semantics).                                                                         | â€œriya did not give her friend any gfits yesterday ğŸ˜Šâ€                                                             |\n",
    "|                                | **Accent / Emoji Handling**                           | Replace emojis or diacritics with textual meaning.                                                                        | â€œriya did not give her friend any gfits yesterday smileâ€                                                          |\n",
    "|                                | **Tokenization**                                      | Split text into words/tokens.                                                                                             | [riya, did, not, give, her, friend, any, gfits, yesterday, smile]                                                 |\n",
    "|                                | **Stopword Removal**                                  | Remove common filler words (optional â€” keep â€œnotâ€ since it affects meaning).                                              | [riya, not, give, friend, gfits, yesterday, smile]                                                                |\n",
    "|                                | **Number / Symbol Handling**                          | Convert numbers/symbols to placeholders (not applicable here).                                                            | â€”                                                                                                                 |\n",
    "|                                | **Stemming / Lemmatization**                          | Convert to base dictionary forms.                                                                                         | [riya, not, give, friend, gfit, yesterday, smile]                                                                 |\n",
    "|                                | **Spell Correction (Edit Distance / Noisy Channel)**  | Fix possible misspellings using distance or probability models.                                                           | â€œgfitâ€ â†’ â€œgiftâ€ (if miswritten)                                                                                  |\n",
    "| **â†’ Output (Lexical Level)**   | Clean, base-level tokens ready for analysis.          | [riya, not, give, friend, gift, yesterday, smile]                                                                         |                                                                                                                   |\n",
    "| **2ï¸âƒ£ Syntactic Processing**   | **POS Tagging**                                       | Assign parts of speech to each token.                                                                                     | Riya/NNP, did/VBD, not/RB, give/VB, her/PRP$, friend/NN, any/DT, gifts/NNS, yesterday/NN, smile/NN                |\n",
    "|                                | **Chunking (Shallow Parsing)**                        | Group words into meaningful phrases (NP, VP, PP, ADVP).                                                                   | [NP Riya] [VP did not give] [NP her friend] [NP any gifts] [ADVP yesterday]                                       |\n",
    "|                                | **Constituency Parsing**                              | Build hierarchical tree (phrase-based).                                                                                   | [S [NP Riya] [VP did [RB not] [VP give [NP her friend] [NP any gifts]]] [ADVP yesterday]]                         |\n",
    "|                                | **Dependency Parsing**                                | Link headâ€“dependent pairs showing direct grammatical relations.                                                           | giveâ†’Riya (nsubj); giveâ†’friend (iobj); giveâ†’gifts (dobj); giveâ†’yesterday (advmod); didâ†’give (aux); giveâ†’not (neg) |\n",
    "|                                | **Grammatical Agreement Checking**                    | Ensure correct subjectâ€“verb, nounâ€“determiner, tense agreement.                                                            | âœ” â€œRiya did not giveâ€¦â€ (3rd person singular + auxiliary â€œdidâ€)                                                    |\n",
    "| **â†’ Output (Syntactic Level)** | Structured relations between words.                   | Head = â€œgiveâ€; Subject = â€œRiyaâ€; Negation = â€œnotâ€; Objects = â€œfriendâ€, â€œgiftsâ€; Modifier = â€œyesterdayâ€                    |                                                                                                                   |\n",
    "| **3ï¸âƒ£ Semantic Processing**    | **Semantic Role Labelling (SRL)**                     | Identify â€œwho did what to whom, when, and how.â€                                                                           | give(agent=Riya, recipient=friend, theme=gift, time=yesterday, polarity=negative)                                 |\n",
    "|                                | **Word Sense Disambiguation (WSD)**                   | Disambiguate polysemous words using context.                                                                              | â€œgiftâ€ â†’ physical present (not talent)                                                                            |\n",
    "|                                | **Coreference Resolution**                            | Link pronouns to entities.                                                                                                | her â†’ Riya                                                                                                        |\n",
    "|                                | **Semantic Parsing**                                  | Convert into logical / graph representation.                                                                              | NOT(give(Riya, friend, gift, yesterday))                                                                          |\n",
    "|                                | **Textual Inference (Optional)**                      | Check if one statement implies another.                                                                                   | â€œRiya didnâ€™t give any giftsâ€ â‡’ implies â€œRiya gave nothing.â€                                                       |\n",
    "|                                | **Sentiment / Emotion Detection (Extended Semantic)** | Interpret emotional cues from words or emoji.                                                                             | â€œsmileâ€ â†’ positive emotion, but negation â€œdid not giveâ€ â†’ neutral/mixed sentiment                                 |\n",
    "| **â†’ Output (Semantic Level)**  | Meaning representation (structured, interpretable).   | {action: give, agent: Riya, recipient: friend, object: gift, time: yesterday, polarity: negative, emotion: mild positive} |                                                                                                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add8e2f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722ded1",
   "metadata": {},
   "source": [
    "```perl\n",
    "NATURAL LANGUAGE PROCESSING (NLP)\n",
    "â”‚\n",
    "â”œâ”€â”€ 1ï¸âƒ£ LINGUISTIC FOUNDATIONS (Theoretical Base)\n",
    "â”‚   â”œâ”€ Phonology â†’ sound patterns & pronunciation\n",
    "â”‚   â”œâ”€ Morphology â†’ internal structure of words\n",
    "â”‚   â”œâ”€ Syntax â†’ grammatical arrangement of words\n",
    "â”‚   â”œâ”€ Semantics â†’ literal meaning of words/sentences\n",
    "â”‚   â””â”€ Pragmatics â†’ intended/contextual meaning\n",
    "â”‚\n",
    "â”œâ”€â”€ 2ï¸âƒ£ LEXICAL PROCESSING (Word-Level)\n",
    "â”‚   â”œâ”€ Text Normalization â†’ cleaning & consistency\n",
    "â”‚   â”‚   â”œâ”€ case conversion, punctuation, numbers\n",
    "â”‚   â”‚   â”œâ”€ contractions, slang, emojis\n",
    "â”‚   â”‚   â””â”€ encoding & whitespace fixes\n",
    "â”‚   â”œâ”€ Tokenization â†’ splitting text into units\n",
    "â”‚   â”‚   â”œâ”€ rule-based, statistical, or subword\n",
    "â”‚   â”‚   â””â”€ levels: word, subword, sentence, character\n",
    "â”‚   â”œâ”€ Stopword Removal â†’ filter common filler words\n",
    "â”‚   â”œâ”€ Morphological Analysis â†’ study of morphemes\n",
    "â”‚   â”‚   â”œâ”€ stemming & lemmatization\n",
    "â”‚   â”‚   â””â”€ normalization of word forms\n",
    "â”‚   â””â”€ String Similarity & Error Models\n",
    "â”‚       â”œâ”€ Edit Distance â†’ # of edits between strings\n",
    "â”‚       â””â”€ Noisy Channel Model â†’ P(w given x) correction\n",
    "â”‚\n",
    "â”œâ”€â”€ 3ï¸âƒ£ SYNTACTIC PROCESSING (Sentence-Level Structure)\n",
    "â”‚   â”œâ”€ POS Tagging â†’ assign grammatical categories\n",
    "â”‚   â”‚   â”œâ”€ rule-based, statistical (HMM), or Brill (hybrid)\n",
    "â”‚   â”œâ”€ Shallow Parsing (Chunking) â†’ detect phrases (NP, VP, PP)\n",
    "â”‚   â”œâ”€ Constituency Parsing â†’ build phrase-structure trees (CFG)\n",
    "â”‚   â”œâ”€ Dependency Parsing â†’ link words via headâ€“dependent relations\n",
    "â”‚   â”œâ”€ Deep Parsing â†’ combine syntax + semantics (who did what to whom)\n",
    "â”‚   â”œâ”€ Parse Tree vs Syntax Tree â†’ derivational vs abstract structure\n",
    "â”‚   â””â”€ Grammatical Agreement Checking â†’ subjectâ€“verb, pronounâ€“noun consistency\n",
    "â”‚\n",
    "â””â”€â”€ 4ï¸âƒ£ SEMANTIC PROCESSING (Meaning-Level)\n",
    "    â”œâ”€ Semantic Role Labelling (SRL) â†’ agent, theme, recipient, time\n",
    "    â”œâ”€ Word Sense Disambiguation (WSD) â†’ resolve polysemy (â€œbankâ€)\n",
    "    â”œâ”€ Semantic Parsing â†’ map sentences to logical/graph meaning\n",
    "    â”œâ”€ Coreference Resolution â†’ link pronouns to entities\n",
    "    â””â”€ Textual Inference & Meaning Representation\n",
    "        â”œâ”€ check entailment & implication (A â‡’ B)\n",
    "        â””â”€ use embeddings/logical forms for reasoning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1de5e",
   "metadata": {},
   "source": [
    "```perl\n",
    "Natural Language Processing (NLP)\n",
    "â”‚\n",
    "â”œâ”€â”€ 1. Linguistic Foundations\n",
    "â”‚   â”œâ”€â”€ Phonology â€“ sound patterns and pronunciation (e.g., \"knight\" vs \"night\")\n",
    "â”‚   â”œâ”€â”€ Morphology â€“ internal structure of words (e.g., un + happy + ness â†’ unhappiness)\n",
    "â”‚   â”œâ”€â”€ Syntax â€“ grammatical arrangement (e.g., \"cat chased dog\" vs \"dog chased cat\")\n",
    "â”‚   â”œâ”€â”€ Semantics â€“ literal meaning of words/sentences (\"light\" â†’ illumination / not heavy)\n",
    "â”‚   â””â”€â”€ Pragmatics â€“ intended meaning in context (\"Can you pass the salt?\" â†’ request)\n",
    "â”‚\n",
    "â”œâ”€â”€ 2. NLP Applications\n",
    "â”‚   â”œâ”€â”€ Information Retrieval â€“ web search queries\n",
    "â”‚   â”œâ”€â”€ E-commerce â€“ product review analysis\n",
    "â”‚   â”œâ”€â”€ Customer Support â€“ chatbots\n",
    "â”‚   â”œâ”€â”€ Healthcare â€“ clinical note analysis\n",
    "â”‚   â”œâ”€â”€ Machine Translation â€“ e.g., Google Translate\n",
    "â”‚   â””â”€â”€ Voice Assistants â€“ Siri, Alexa, Google Assistant\n",
    "â”‚\n",
    "â”œâ”€â”€ 3. Text Normalization\n",
    "â”‚   â”œâ”€â”€ Basic Normalization Tasks\n",
    "â”‚   â”‚   â”œâ”€â”€ Case conversion â€“ â€œNatural Languageâ€ â†’ â€œnatural languageâ€\n",
    "â”‚   â”‚   â”œâ”€â”€ Punctuation & symbol handling â€“ â€œC++â€ â†’ keep â€œ++â€\n",
    "â”‚   â”‚   â”œâ”€â”€ Number standardization â€“ â€œten kgâ€ â†’ â€œ10 kgâ€\n",
    "â”‚   â”‚   â”œâ”€â”€ Contraction expansion â€“ â€œdonâ€™tâ€ â†’ â€œdo notâ€\n",
    "â”‚   â”‚   â”œâ”€â”€ Accent removal â€“ â€œrÃ©sumÃ©â€ â†’ â€œresumeâ€\n",
    "â”‚   â”‚   â””â”€â”€ Whitespace & encoding fixes â€“ standardize UTF-8, remove extra spaces\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ Advanced Normalization Tasks\n",
    "â”‚       â”œâ”€â”€ Slang/abbreviation expansion â€“ â€œbtwâ€ â†’ â€œby the wayâ€\n",
    "â”‚       â”œâ”€â”€ Unicode & emoji handling â€“ ğŸ˜Š â†’ â€œsmileâ€\n",
    "â”‚       â””â”€â”€ Text standardization pipelines â€“ regex/rule-based pipelines for canonical input\n",
    "â”‚\n",
    "â”œâ”€â”€ 4. Tokenization\n",
    "â”‚   â”œâ”€â”€ Levels\n",
    "â”‚   â”‚   â”œâ”€â”€ Multi-Word-level â€“ \"Combined words not to be broken\" â†’ [\"out-of-office\"]\n",
    "â”‚   â”‚   â”œâ”€â”€ Word-level â€“ â€œLanguage models are powerfulâ€ â†’ [language, models, are, powerful]\n",
    "â”‚   â”‚   â”œâ”€â”€ Subword-level â€“ â€œunhappinessâ€ â†’ [un, happy, ness]\n",
    "â”‚   â”‚   â”œâ”€â”€ Sentence-level â€“ split paragraphs into sentences\n",
    "â”‚   â”‚   â””â”€â”€ Character-level â€“ â€œcatâ€ â†’ [c, a, t]\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ Approaches\n",
    "â”‚   â”‚   â”œâ”€â”€ Rule-based / Regex Tokenizers â€“ predefined delimiters; fast but brittle\n",
    "â”‚   â”‚   â”œâ”€â”€ Statistical Tokenizers â€“ learn boundaries (esp. for Chinese, Japanese)\n",
    "â”‚   â”‚   â””â”€â”€ Subword Algorithms â€“ BPE, WordPiece (used in BERT, GPT)\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ Challenges\n",
    "â”‚       â”œâ”€â”€ Ambiguous boundaries (no spaces in Thai/Chinese)\n",
    "â”‚       â”œâ”€â”€ Multiword expressions (â€œNew York Cityâ€)\n",
    "â”‚       â”œâ”€â”€ Punctuation ambiguity (â€œU.S.â€ vs sentence end)\n",
    "â”‚       â”œâ”€â”€ Contractions (â€œdonâ€™tâ€ â†’ [do, not])\n",
    "â”‚       â”œâ”€â”€ URLs & emojis (<URL>, <EMOJI>)\n",
    "â”‚       â””â”€â”€ Importance â€“ controls vocabulary, improves model efficiency\n",
    "â”‚\n",
    "â”œâ”€â”€ 5. Stopword Removal\n",
    "â”‚   â”œâ”€â”€ Goal â€“ remove common words that add little meaning (â€œtheâ€, â€œisâ€, â€œofâ€)\n",
    "â”‚   â”œâ”€â”€ Benefits\n",
    "â”‚   â”‚   â”œâ”€â”€ Reduces dimensionality\n",
    "â”‚   â”‚   â”œâ”€â”€ Improves focus on meaningful words\n",
    "â”‚   â”‚   â”œâ”€â”€ Reduces noise in BoW/TF-IDF\n",
    "â”‚   â”‚   â””â”€â”€ Simplifies keyword matching in search\n",
    "â”‚   â”œâ”€â”€ Challenges\n",
    "â”‚   â”‚   â”œâ”€â”€ Task sensitivity â€“ â€œnotâ€, â€œneverâ€ important in sentiment analysis\n",
    "â”‚   â”‚   â”œâ”€â”€ Domain dependence â€“ generic lists may drop important domain words\n",
    "â”‚   â”‚   â””â”€â”€ Language dependence â€“ different stopword lists per language\n",
    "â”‚\n",
    "â”œâ”€â”€ 6. Morphological Analysis\n",
    "â”‚   â”œâ”€â”€ Morpheme Types\n",
    "â”‚   â”‚   â”œâ”€â”€ Free â€“ can stand alone (â€œbookâ€, â€œhappyâ€)\n",
    "â”‚   â”‚   â”œâ”€â”€ Bound â€“ prefixes/suffixes (â€œun-â€, â€œ-nessâ€)\n",
    "â”‚   â”‚   â”œâ”€â”€ Prefix â€“ before root (â€œunhappyâ€)\n",
    "â”‚   â”‚   â”œâ”€â”€ Suffix â€“ after root (â€œkindnessâ€)\n",
    "â”‚   â”‚   â”œâ”€â”€ Root/Stem â€“ main meaning carrier (â€œplayâ€)\n",
    "â”‚   â”‚   â””â”€â”€ Infix/Circumfix â€“ embedded or wrapped (rare in English)\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ Functions in NLP\n",
    "â”‚   â”‚   â”œâ”€â”€ Vocabulary normalization â€“ groups inflected forms\n",
    "â”‚   â”‚   â”œâ”€â”€ POS tagging â€“ identifies tense, number, degree\n",
    "â”‚   â”‚   â”œâ”€â”€ Semantic clarity â€“ link related forms (create, creator, creation)\n",
    "â”‚   â”‚   â””â”€â”€ Downstream utility â€“ stemming, lemmatization, spell correction\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ Approaches\n",
    "â”‚   â”‚   â”œâ”€â”€ Rule-based morphological analyzers â€“ handcrafted linguistic rules\n",
    "â”‚   â”‚   â””â”€â”€ Statistical analyzers â€“ learned from corpora using CRFs/neural models\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ Applications\n",
    "â”‚       â”œâ”€â”€ Information Retrieval â€“ group â€œrunâ€, â€œrunningâ€, â€œranâ€\n",
    "â”‚       â”œâ”€â”€ Machine Translation â€“ maintain agreement\n",
    "â”‚       â”œâ”€â”€ Speech Recognition â€“ handle variants\n",
    "â”‚       â””â”€â”€ Text-to-Speech â€“ ensure correct pronunciation\n",
    "â”‚\n",
    "â”œâ”€â”€ 7. Stemming vs Lemmatization\n",
    "â”‚   â”œâ”€â”€ Stemming\n",
    "â”‚   â”‚   â”œâ”€â”€ Rule-based truncation of suffixes/prefixes (e.g., Porter Stemmer)\n",
    "â”‚   â”‚   â”œâ”€â”€ Output may be non-words (studies â†’ studi)\n",
    "â”‚   â”‚   â”œâ”€â”€ Fast but crude, language-specific\n",
    "â”‚   â”‚   â”œâ”€â”€ Common Algorithms:\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ Porter Stemmer (1980)\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ Snowball Stemmer (Porter2, 2001, multilingual, improved)\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ Lancaster Stemmer (more aggressive)\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ Lemmatization\n",
    "â”‚   â”‚   â”œâ”€â”€ Linguistic normalization using POS and morphological analysis\n",
    "â”‚   â”‚   â”œâ”€â”€ Always produces valid dictionary words (studies â†’ study)\n",
    "â”‚   â”‚   â”œâ”€â”€ Handles irregulars (went â†’ go, better â†’ good)\n",
    "â”‚   â”‚   â”œâ”€â”€ Slower but more accurate\n",
    "â”‚   â”‚   â””â”€â”€ Uses WordNet, spaCy, or Stanza\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ Comparison Summary\n",
    "â”‚       â”œâ”€â”€ Stemming â†’ fast, rule-based, less accurate\n",
    "â”‚       â”œâ”€â”€ Lemmatization â†’ slower, semantic, more precise\n",
    "â”‚       â””â”€â”€ Use cases:\n",
    "â”‚           â”œâ”€â”€ Stemming â†’ search, topic modeling, IR\n",
    "â”‚           â””â”€â”€ Lemmatization â†’ semantic analysis, MT, QA\n",
    "â”‚\n",
    "â”œâ”€â”€ 8. String Similarity & Error Handling\n",
    "â”‚   â”œâ”€â”€ Edit Distance (Levenshtein Distance)\n",
    "â”‚   â”‚   â”œâ”€â”€ Measures minimal edits (insert, delete, substitute)\n",
    "â”‚   â”‚   â”œâ”€â”€ Example: kitten â†’ sitting = 3 edits\n",
    "â”‚   â”‚   â”œâ”€â”€ Applications:\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ Spell correction\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ DNA sequence analysis\n",
    "â”‚   â”‚   â”‚   â”œâ”€â”€ Fuzzy search\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ Plagiarism detection\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ Noisy Channel Model\n",
    "â”‚       â”œâ”€â”€ Formula: P(w given x) âˆ P(x given w) Ã— P(w)\n",
    "â”‚       â”œâ”€â”€ Components:\n",
    "â”‚       â”‚   â”œâ”€â”€ Language Model (P(w)) â†’ how likely a word is\n",
    "â”‚       â”‚   â””â”€â”€ Error Model (P(x given w)) â†’ how likely that word caused the observed error\n",
    "â”‚       â”œâ”€â”€ Example:\n",
    "â”‚       â”‚   â”œâ”€â”€ Observed: â€œspelingâ€\n",
    "â”‚       â”‚   â”œâ”€â”€ Candidates:\n",
    "â”‚       â”‚   â”‚   â€¢ spelling â†’ P(w)=0.0012, P(x|w)=0.5 â‡’ 0.0006 âœ…\n",
    "â”‚       â”‚   â”‚   â€¢ spieling â†’ 0.0001Ã—0.5=0.00005\n",
    "â”‚       â”‚   â”‚   â€¢ selling â†’ 0.0011Ã—0.05=0.000055\n",
    "â”‚       â”œâ”€â”€ Result: â€œspellingâ€ wins (most probable)\n",
    "â”‚       â”œâ”€â”€ Applications:\n",
    "â”‚       â”‚   â”œâ”€â”€ Spell correction\n",
    "â”‚       â”‚   â”œâ”€â”€ OCR & ASR error correction\n",
    "â”‚       â”‚   â”œâ”€â”€ Query auto-correction\n",
    "â”‚       â”‚   â””â”€â”€ Text normalization\n",
    "â”‚\n",
    "â””â”€â”€ 9. Summary of Preprocessing Pipeline\n",
    "    â”œâ”€â”€ Text Cleaning â†’ (normalize, handle noise)\n",
    "    â”œâ”€â”€ Tokenization â†’ (split text)\n",
    "    â”œâ”€â”€ Stopword Removal â†’ (filter common words)\n",
    "    â”œâ”€â”€ Morphological Processing â†’ (stem/lemma)\n",
    "    â”œâ”€â”€ String Similarity â†’ (detect/correct errors)\n",
    "    â””â”€â”€ Statistical Models â†’ (e.g., Noisy Channel, Language Models)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234b73c",
   "metadata": {},
   "source": [
    "## Cheatsheet\n",
    "```prel\n",
    "SEMANTIC PROCESSING\n",
    "â”‚\n",
    "â”œâ”€â”€ 1ï¸âƒ£ LEXICAL PROCESSING (Word-Level)\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Text Normalisation\n",
    "â”‚   â”‚   â”œâ”€ Case Conversion â†’ (\"Natural Language\" â†’ \"natural language\")\n",
    "â”‚   â”‚   â”œâ”€ Punctuation & Symbol Handling â†’ (\"C++\" â†’ keep; \"Hello!!!\" â†’ \"hello\")\n",
    "â”‚   â”‚   â”œâ”€ Number Standardisation â†’ (\"ten kg\" â†’ \"<NUM> kg\")\n",
    "â”‚   â”‚   â”œâ”€ Contraction Expansion â†’ (\"donâ€™t\" â†’ \"do not\")\n",
    "â”‚   â”‚   â”œâ”€ Accent Removal â†’ (\"rÃ©sumÃ©\" â†’ \"resume\")\n",
    "â”‚   â”‚   â”œâ”€ Slang & Abbreviation Expansion â†’ (\"btw\" â†’ \"by the way\")\n",
    "â”‚   â”‚   â””â”€ Unicode / Emoji Handling â†’ (â¤ï¸ â†’ \"heart\")\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Tokenisation\n",
    "â”‚   â”‚   â”œâ”€ Word-Level â†’ \"Language models are powerful.\"\n",
    "â”‚   â”‚   â”œâ”€ Subword-Level â†’ \"unhappiness\" â†’ [un, happy, ness]\n",
    "â”‚   â”‚   â”œâ”€ Sentence-Level â†’ \"It rained. Roads flooded.\"\n",
    "â”‚   â”‚   â”œâ”€ Character-Level â†’ \"cat\" â†’ [c, a, t]\n",
    "â”‚   â”‚   â””â”€ Approaches\n",
    "â”‚   â”‚       â”œâ”€ Rule-Based (regex)\n",
    "â”‚   â”‚       â”œâ”€ Statistical (CRF-based)\n",
    "â”‚   â”‚       â””â”€ Subword Algorithms (BPE, WordPiece)\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Stopword Removal\n",
    "â”‚   â”‚   â”œâ”€ Removes frequent filler words (â€œisâ€, â€œtheâ€, â€œofâ€)\n",
    "â”‚   â”‚   â”œâ”€ Task-Sensitive â†’ Keep â€œnotâ€ in sentiment analysis\n",
    "â”‚   â”‚   â””â”€ Domain-Specific Lists â†’ Biomedical text â‰  News text\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€ ğŸ”¹ Morphological Analysis\n",
    "â”‚       â”œâ”€ Morphemes: smallest meaning units\n",
    "â”‚       â”‚   â”œâ”€ Free: â€œbookâ€   â”œâ”€ Bound: â€œ-nessâ€, â€œun-â€\n",
    "â”‚       â”‚   â”œâ”€ Prefix: â€œun-â€  â”œâ”€ Suffix: â€œ-ingâ€\n",
    "â”‚       â”‚   â”œâ”€ Root: â€œplayâ€   â””â”€ Infix: (rare, e.g., Tagalog â€œumâ€)\n",
    "â”‚       â”œâ”€ Stemming â†’ \"studies\" â†’ \"studi\"\n",
    "â”‚       â”œâ”€ Lemmatization â†’ \"studies\" â†’ \"study\"\n",
    "â”‚       â”œâ”€ Tools:\n",
    "â”‚       â”‚   â”œâ”€ Porter Stemmer â†’ rule-based suffix stripping\n",
    "â”‚       â”‚   â””â”€ Snowball Stemmer â†’ improved version (supports more langs)\n",
    "â”‚       â””â”€ NLP Use â†’ vocabulary normalization, POS tagging, IR, MT\n",
    "â”‚\n",
    "â”œâ”€â”€ 2ï¸âƒ£ SYNTACTIC PROCESSING (Sentence-Level)\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ POS Tagging\n",
    "â”‚   â”‚   â”œâ”€ Rule-Based â†’ Uses lexicons + context rules\n",
    "â”‚   â”‚   â”œâ”€ Statistical â†’ Learns probabilities (P(tag|word), P(tag|prev tag))\n",
    "â”‚   â”‚   â””â”€ Transformation-Based (Brill Tagger)\n",
    "â”‚   â”‚       â†’ Learns correction rules over baseline tagging\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Shallow Parsing (Chunking)\n",
    "â”‚   â”‚   â”œâ”€ Groups words â†’ [NP], [VP], [PP]\n",
    "â”‚   â”‚   â”œâ”€ IOB Tagging â†’ B-NP, I-NP, O\n",
    "â”‚   â”‚   â”œâ”€ Example â†’ [NP The quick brown fox] [VP jumps]\n",
    "â”‚   â”‚   â””â”€ Use â†’ NER, Relation Extraction\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Constituency Parsing\n",
    "â”‚   â”‚   â”œâ”€ Based on Context-Free Grammar (CFG)\n",
    "â”‚   â”‚   â”œâ”€ Builds hierarchical structure: NP, VP, PP\n",
    "â”‚   â”‚   â”œâ”€ Example: [S [NP The cat] [VP chased [NP the dog]]]\n",
    "â”‚   â”‚   â””â”€ Output â†’ Parse Tree (phrase structure)\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Dependency Parsing\n",
    "â”‚   â”‚   â”œâ”€ Connects words via relations â†’ (head â†’ dependent)\n",
    "â”‚   â”‚   â”œâ”€ Example â†’ jumpsâ†’fox(nsubj), jumpsâ†’dog(pobj)\n",
    "â”‚   â”‚   â”œâ”€ Output â†’ Directed Graph\n",
    "â”‚   â”‚   â”œâ”€ Types:\n",
    "â”‚   â”‚   â”‚   â”œâ”€ Rule-Based\n",
    "â”‚   â”‚   â”‚   â”œâ”€ Transition-Based\n",
    "â”‚   â”‚   â”‚   â”œâ”€ Graph-Based\n",
    "â”‚   â”‚   â”‚   â””â”€ Neural (e.g., spaCy)\n",
    "â”‚   â”‚   â””â”€ Use â†’ Relation Extraction, Semantic Parsing\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Parse Trees vs Syntax Trees\n",
    "â”‚   â”‚   â”œâ”€ Parse Tree â†’ Step-by-step grammar derivation (CFG)\n",
    "â”‚   â”‚   â”œâ”€ Syntax Tree â†’ Abstracted grammatical structure\n",
    "â”‚   â”‚   â””â”€ Relation â†’ Syntax tree = simplified form of parse tree\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€ ğŸ”¹ Deep Parsing\n",
    "â”‚   â”‚   â”œâ”€ Combines syntax + semantics\n",
    "â”‚   â”‚   â”œâ”€ Adds meaning roles (who did what to whom)\n",
    "â”‚   â”‚   â”œâ”€ Example:\n",
    "â”‚   â”‚   â”‚   Sentence: â€œRiya gave her friend a gift yesterday.â€\n",
    "â”‚   â”‚   â”‚   â†’ agent(Riya), recipient(friend), theme(gift), time(yesterday)\n",
    "â”‚   â”‚   â”œâ”€ Builds â†’ Syntactic Tree + Semantic Graph\n",
    "â”‚   â”‚   â””â”€ Use â†’ QA, Dialogue, Translation, Semantic Role Labelling\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€ ğŸ”¹ Grammatical Agreement Checking\n",
    "â”‚       â”œâ”€ Ensures words agree in number, person, gender, tense\n",
    "â”‚       â”œâ”€ Example:\n",
    "â”‚       â”‚   - âœ” â€œShe writes a letter.â€ / âœ˜ â€œShe write a letter.â€\n",
    "â”‚       â”‚   - âœ” â€œThese apples are sweet.â€ / âœ˜ â€œThis apples are sweet.â€\n",
    "â”‚       â”œâ”€ Checks â†’ Subjectâ€“Verb, Pronounâ€“Noun, Determinerâ€“Noun\n",
    "â”‚       â””â”€ Use â†’ Grammar checkers, MT, Text evaluation\n",
    "â”‚\n",
    "â””â”€â”€ 3ï¸âƒ£ SEMANTIC PROCESSING (Meaning-Level)\n",
    "    â”‚\n",
    "    â”œâ”€ ğŸ”¹ Semantic Role Labelling (SRL)\n",
    "    â”‚   â”œâ”€ Identifies roles â†’ agent, theme, recipient, location, time\n",
    "    â”‚   â”œâ”€ Example â†’ give(Riya, gift, friend), time(give, yesterday)\n",
    "    â”‚   â””â”€ Connects syntax â†’ meaning\n",
    "    â”‚\n",
    "    â”œâ”€ ğŸ”¹ Word Sense Disambiguation (WSD)\n",
    "    â”‚   â”œâ”€ Resolves polysemy â†’ â€œbankâ€ = riverbank vs. financial institution\n",
    "    â”‚   â”œâ”€ Uses â†’ Context words, corpora (WordNet)\n",
    "    â”‚   â””â”€ Use â†’ Translation, QA, IR\n",
    "    â”‚\n",
    "    â”œâ”€ ğŸ”¹ Semantic Parsing\n",
    "    â”‚   â”œâ”€ Converts text â†’ formal meaning representations (logic/graph)\n",
    "    â”‚   â”œâ”€ Example â†’ â€œRiya gave a giftâ€ â†’ give(Riya, gift)\n",
    "    â”‚   â””â”€ Foundation for â†’ QA, Dialogue Systems\n",
    "    â”‚\n",
    "    â”œâ”€ ğŸ”¹ Coreference Resolution\n",
    "    â”‚   â”œâ”€ Links pronouns to antecedents â†’ â€œRiya lost her pen.â€ â†’ her â†’ Riya\n",
    "    â”‚   â””â”€ Improves â†’ Text summarization, dialogue coherence\n",
    "    â”‚\n",
    "    â””â”€ ğŸ”¹ Textual Inference & Meaning Representation\n",
    "        â”œâ”€ Checks if one sentence implies another â†’ (Riya bought a car â‡’ She owns a car)\n",
    "        â”œâ”€ Uses â†’ Logical forms, embeddings, contextual models\n",
    "        â””â”€ Applications â†’ QA, NLI (Natural Language Inference)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0304a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
